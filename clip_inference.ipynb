{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c710bc00",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2e2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import torch\n",
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from zero_dce import (\n",
    "    Trainer, plot_result\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b1da0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "# print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n",
    "model = SentenceTransformer('clip-ViT-L-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb507653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_images_with_zero_dce(full_image_paths, model_weights_path):\n",
    "    trainer = Trainer()\n",
    "    trainer.build_model(pretrain_weights=model_weights_path)\n",
    "\n",
    "    enhanced_paths = []\n",
    "\n",
    "    for path in full_image_paths:\n",
    "        path = os.path.normpath(path)\n",
    "        image, enhanced = trainer.infer_gpu(path, image_resize_factor=1)\n",
    "\n",
    "        alpha = 0.4\n",
    "        enhanced_toned = alpha * enhanced + (1 - alpha) * np.asarray(image) / 255.0\n",
    "        enhanced_toned = np.clip(enhanced_toned, 0, 1)\n",
    "\n",
    "        enhanced_path = path.replace(\"tpc-imgs\", \"enhanced-imgs\")\n",
    "        os.makedirs(os.path.dirname(enhanced_path), exist_ok=True)\n",
    "        Image.fromarray((enhanced_toned * 255).astype(np.uint8)).save(enhanced_path)\n",
    "\n",
    "        enhanced_paths.append(enhanced_path)\n",
    "\n",
    "    return enhanced_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8340e6",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d685e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load prompts and unique labels from JSON\n",
    "def load_dataset(json_path):\n",
    "    with open(json_path) as f:\n",
    "        data = json.load(f)\n",
    "    # image_paths = ['/content/' + entry['image_path'] for entry in data]\n",
    "    image_paths = ['C:\\College\\Semester 4\\Research\\\\' + entry['image_path'] for entry in data]\n",
    "    descriptions = [entry['description'] for entry in data]\n",
    "    slangs = [entry['slang'] for entry in data]\n",
    "    # slangs = [entry['label'] for entry in data]\n",
    "\n",
    "    label_to_desc = {}\n",
    "    for desc, slang in zip(descriptions, slangs):\n",
    "        label_to_desc[slang] = desc\n",
    "\n",
    "    unique_slangs = list(label_to_desc.keys())\n",
    "    unique_descriptions = list(label_to_desc.values())\n",
    "\n",
    "    return image_paths, slangs, unique_slangs, unique_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dd6e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Encode descriptions into text embeddings\n",
    "def encode_text_prompts(model, descriptions):\n",
    "    text_embeddings = model.encode(descriptions, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    return text_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f5e652",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab2848f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Run inference on images, returning predicted slang labels\n",
    "def run_inference_batch(image_paths, model, text_embeddings, unique_slangs, batch_size=5):\n",
    "    predictions = []\n",
    "    imgs_batch = []\n",
    "\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        imgs_batch.append(img)\n",
    "\n",
    "        if (i + 1) % batch_size == 0 or (i + 1) == len(image_paths):\n",
    "            img_embs = model.encode(imgs_batch, convert_to_tensor=True, normalize_embeddings=True)\n",
    "            cos_sim = util.cos_sim(img_embs, text_embeddings)\n",
    "            pred_idxs = cos_sim.argmax(dim=1).tolist()\n",
    "            for idx in pred_idxs:\n",
    "                predictions.append(unique_slangs[idx])\n",
    "            imgs_batch = []\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11620549",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f64660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Evaluate predictions with accuracy, precision, recall, and confusion matrix\n",
    "def evaluate(true_labels, pred_labels, unique_slangs):\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    precision = precision_score(true_labels, pred_labels, labels=unique_slangs, average=None, zero_division=0)\n",
    "    recall = recall_score(true_labels, pred_labels, labels=unique_slangs, average=None, zero_division=0)\n",
    "    cm = confusion_matrix(true_labels, pred_labels, labels=unique_slangs)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\\n\")\n",
    "\n",
    "    for i, label in enumerate(unique_slangs):\n",
    "        print(f\"Label: {label}\")\n",
    "        print(f\"  Precision: {precision[i]:.3f}\")\n",
    "        print(f\"  Recall:    {recall[i]:.3f}\\n\")\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5841e01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\College\\Semester 4\\Research\\venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\College\\Semester 4\\Research\n",
      "[INFO] Unbalanced dataset detected — applying Zero-DCE enhancement...\n",
      "[INFO] Running inference...\n",
      "[INFO] Evaluating...\n",
      "Accuracy: 75.00%\n",
      "\n",
      "Label: Virginia creeper\n",
      "  Precision: 0.933\n",
      "  Recall:    0.718\n",
      "\n",
      "Label: Boxelder\n",
      "  Precision: 0.500\n",
      "  Recall:    0.846\n",
      "\n",
      "Confusion Matrix:\n",
      "[[28 11]\n",
      " [ 2 11]]\n"
     ]
    }
   ],
   "source": [
    "%cd /College/Semester 4/Research\n",
    "%pwd\n",
    "# Cell 6: Main script - load data, model, run inference, evaluate\n",
    "if __name__ == \"__main__\":\n",
    "    # json_path = \"/content/metadata_balanced.json\"\n",
    "    json_path = \"metadata_unbalanced.json\"  # or \"metadata_balanced.json\"\n",
    "    base_dir = \"C:/College/Semester 4/Research\"\n",
    "    model_weights_path = r\"C:/College/Semester 4/Research/Zero-DCE/pretrained-models/model200_dark_faces.pth\"\n",
    "\n",
    "    image_paths, true_slangs, unique_slangs, unique_descriptions = load_dataset(json_path)\n",
    "    image_paths = [os.path.join(base_dir, p) for p in image_paths]\n",
    "\n",
    "    if \"unbalanced\" in json_path.lower():\n",
    "        print(\"[INFO] Unbalanced dataset detected — applying Zero-DCE enhancement...\")\n",
    "        image_paths = enhance_images_with_zero_dce(\n",
    "            full_image_paths=image_paths,\n",
    "            model_weights_path=model_weights_path\n",
    "        )\n",
    "        \n",
    "    text_emb = encode_text_prompts(model, unique_descriptions)\n",
    "\n",
    "    print(\"[INFO] Running inference...\")\n",
    "    predicted_slangs = run_inference_batch(image_paths, model, text_emb, unique_slangs)\n",
    "\n",
    "    print(\"[INFO] Evaluating...\")\n",
    "    evaluate(true_slangs, predicted_slangs, unique_slangs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
